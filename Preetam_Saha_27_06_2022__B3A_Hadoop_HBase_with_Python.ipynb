{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preetam Saha_27.06.2022_ B3A Hadoop HBase with Python",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/Hadoop_Hbase_practice/blob/main/Preetam_Saha_27_06_2022__B3A_Hadoop_HBase_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYTQEpb1htS"
      },
      "source": [
        "#Hadoop \n",
        "Install and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0IOmlc0-Dt"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWspfH6A1a4P",
        "outputId": "170111a2-c90f-46a1-9e33-b42b2202a2d5"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "#!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.3/hadoop-3.3.3.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "#!tar -xzf hadoop-3.3.0.tar.gz\n",
        "!tar -xzf hadoop-3.3.3.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "#!mv  hadoop-3.3.0/ /usr/local/\n",
        "!mv  hadoop-3.3.3/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 05:22:04--  https://downloads.apache.org/hadoop/common/hadoop-3.3.3/hadoop-3.3.3.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 645040598 (615M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.3.tar.gz’\n",
            "\n",
            "hadoop-3.3.3.tar.gz 100%[===================>] 615.16M  26.6MB/s    in 26s     \n",
            "\n",
            "2022-06-27 05:22:30 (24.0 MB/s) - ‘hadoop-3.3.3.tar.gz’ saved [645040598/645040598]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24QjQ22V1swJ"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugibq3m1CbgC"
      },
      "source": [
        "## Set Hadoop Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7WFh5k18E1"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "#os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.0/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.3/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaaMpfVP2p3m"
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# current_path taken from last command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.3/bin/'\n",
        "os.environ[\"PATH\"] = new_path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD34gT3y2u-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131c1e7a-f7b6-4168-817c-17cf48a29a23"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000\n",
        "#!hadoop jar /usr/local/hadoop-3.3.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.3.jar pi 16 100000"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Maps  = 16\n",
            "Samples per Map = 100000\n",
            "Wrote input for Map #0\n",
            "Wrote input for Map #1\n",
            "Wrote input for Map #2\n",
            "Wrote input for Map #3\n",
            "Wrote input for Map #4\n",
            "Wrote input for Map #5\n",
            "Wrote input for Map #6\n",
            "Wrote input for Map #7\n",
            "Wrote input for Map #8\n",
            "Wrote input for Map #9\n",
            "Wrote input for Map #10\n",
            "Wrote input for Map #11\n",
            "Wrote input for Map #12\n",
            "Wrote input for Map #13\n",
            "Wrote input for Map #14\n",
            "Wrote input for Map #15\n",
            "Starting Job\n",
            "2022-06-27 05:25:13,255 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-06-27 05:25:13,359 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-06-27 05:25:13,360 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-06-27 05:25:13,491 INFO input.FileInputFormat: Total input files to process : 16\n",
            "2022-06-27 05:25:13,522 INFO mapreduce.JobSubmitter: number of splits:16\n",
            "2022-06-27 05:25:13,722 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1780158170_0001\n",
            "2022-06-27 05:25:13,722 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-06-27 05:25:13,916 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-06-27 05:25:13,917 INFO mapreduce.Job: Running job: job_local1780158170_0001\n",
            "2022-06-27 05:25:13,924 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-06-27 05:25:13,932 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:13,932 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:13,933 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2022-06-27 05:25:14,008 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-06-27 05:25:14,009 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000000_0\n",
            "2022-06-27 05:25:14,037 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,037 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,077 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,083 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part12:0+118\n",
            "2022-06-27 05:25:14,165 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,165 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,165 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,165 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,165 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,169 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,204 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,204 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,204 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,204 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,204 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,211 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,225 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,227 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,227 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000000_0' done.\n",
            "2022-06-27 05:25:14,237 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=283445\n",
            "\t\tFILE: Number of bytes written=923553\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,237 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000000_0\n",
            "2022-06-27 05:25:14,238 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000001_0\n",
            "2022-06-27 05:25:14,239 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,239 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,240 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,241 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part6:0+118\n",
            "2022-06-27 05:25:14,318 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,318 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,318 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,318 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,318 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,319 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,329 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,329 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,329 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,329 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,329 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,332 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,334 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000001_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,335 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,336 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000001_0' done.\n",
            "2022-06-27 05:25:14,336 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=285644\n",
            "\t\tFILE: Number of bytes written=923613\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=363855872\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,336 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000001_0\n",
            "2022-06-27 05:25:14,336 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000002_0\n",
            "2022-06-27 05:25:14,337 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,337 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,338 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,339 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part1:0+118\n",
            "2022-06-27 05:25:14,407 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,407 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,407 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,407 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,407 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,408 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,417 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,418 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,418 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,418 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,418 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,419 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,421 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000002_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,423 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,423 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000002_0' done.\n",
            "2022-06-27 05:25:14,423 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=287843\n",
            "\t\tFILE: Number of bytes written=923673\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=469237760\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,423 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000002_0\n",
            "2022-06-27 05:25:14,424 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000003_0\n",
            "2022-06-27 05:25:14,425 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,425 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,425 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,426 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part14:0+118\n",
            "2022-06-27 05:25:14,502 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,503 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,503 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,503 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,503 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,503 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,512 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,513 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,513 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,513 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,513 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,516 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,520 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000003_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,521 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,522 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000003_0' done.\n",
            "2022-06-27 05:25:14,526 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=290042\n",
            "\t\tFILE: Number of bytes written=923733\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=574619648\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,526 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000003_0\n",
            "2022-06-27 05:25:14,526 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000004_0\n",
            "2022-06-27 05:25:14,527 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,527 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,527 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,529 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part2:0+118\n",
            "2022-06-27 05:25:14,599 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,599 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,599 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,599 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,599 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,601 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,608 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,608 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,608 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,608 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,608 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,610 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,614 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000004_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,616 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,617 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000004_0' done.\n",
            "2022-06-27 05:25:14,618 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=291729\n",
            "\t\tFILE: Number of bytes written=923793\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=680001536\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,618 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000004_0\n",
            "2022-06-27 05:25:14,618 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000005_0\n",
            "2022-06-27 05:25:14,620 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,620 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,620 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,622 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part15:0+118\n",
            "2022-06-27 05:25:14,685 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,685 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,685 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,685 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,685 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,686 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,690 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,691 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,691 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,691 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,691 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,692 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,695 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000005_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,696 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,696 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000005_0' done.\n",
            "2022-06-27 05:25:14,697 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=293416\n",
            "\t\tFILE: Number of bytes written=923853\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=785383424\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,697 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000005_0\n",
            "2022-06-27 05:25:14,697 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000006_0\n",
            "2022-06-27 05:25:14,701 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,701 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,702 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,712 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part10:0+118\n",
            "2022-06-27 05:25:14,775 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,775 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,775 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,775 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,775 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,776 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,782 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,782 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,782 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,782 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,782 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,783 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,784 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000006_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,786 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,786 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000006_0' done.\n",
            "2022-06-27 05:25:14,786 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=295103\n",
            "\t\tFILE: Number of bytes written=923913\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=890765312\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,786 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000006_0\n",
            "2022-06-27 05:25:14,786 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000007_0\n",
            "2022-06-27 05:25:14,790 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,790 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,790 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,792 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part5:0+118\n",
            "2022-06-27 05:25:14,862 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,862 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,862 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,862 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,862 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,863 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,871 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,871 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,871 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,871 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,871 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,873 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,875 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000007_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,876 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,876 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000007_0' done.\n",
            "2022-06-27 05:25:14,876 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000007_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=296790\n",
            "\t\tFILE: Number of bytes written=923973\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=996147200\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,876 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000007_0\n",
            "2022-06-27 05:25:14,877 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000008_0\n",
            "2022-06-27 05:25:14,877 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,877 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,878 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,879 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part11:0+118\n",
            "2022-06-27 05:25:14,922 INFO mapreduce.Job: Job job_local1780158170_0001 running in uber mode : false\n",
            "2022-06-27 05:25:14,924 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-06-27 05:25:14,942 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:14,942 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:14,942 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:14,942 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,942 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:14,943 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:14,949 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:14,949 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:14,949 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:14,949 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:14,949 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:14,951 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:14,952 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000008_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:14,956 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:14,956 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000008_0' done.\n",
            "2022-06-27 05:25:14,956 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000008_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=297965\n",
            "\t\tFILE: Number of bytes written=924033\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1101529088\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:14,956 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000008_0\n",
            "2022-06-27 05:25:14,956 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000009_0\n",
            "2022-06-27 05:25:14,957 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:14,957 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:14,958 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:14,959 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part4:0+118\n",
            "2022-06-27 05:25:15,024 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,024 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,024 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,024 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,024 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,025 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,029 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,030 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,030 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,030 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,030 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,031 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,036 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000009_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,039 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,042 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000009_0' done.\n",
            "2022-06-27 05:25:15,042 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000009_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=299140\n",
            "\t\tFILE: Number of bytes written=924093\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1206910976\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,042 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000009_0\n",
            "2022-06-27 05:25:15,042 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000010_0\n",
            "2022-06-27 05:25:15,051 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,051 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,051 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,053 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part9:0+118\n",
            "2022-06-27 05:25:15,139 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,139 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,139 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,139 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,139 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,141 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,148 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,148 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,148 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,148 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,148 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,150 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,153 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000010_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,169 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,169 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000010_0' done.\n",
            "2022-06-27 05:25:15,169 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000010_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=300315\n",
            "\t\tFILE: Number of bytes written=924153\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1312292864\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,170 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000010_0\n",
            "2022-06-27 05:25:15,170 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000011_0\n",
            "2022-06-27 05:25:15,171 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,171 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,171 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,173 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part0:0+118\n",
            "2022-06-27 05:25:15,240 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,240 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,240 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,240 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,240 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,241 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,246 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,247 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,247 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,247 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,247 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,248 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,250 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000011_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,275 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,275 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000011_0' done.\n",
            "2022-06-27 05:25:15,276 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000011_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=301490\n",
            "\t\tFILE: Number of bytes written=924213\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1417674752\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,276 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000011_0\n",
            "2022-06-27 05:25:15,276 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000012_0\n",
            "2022-06-27 05:25:15,279 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,279 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,279 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,280 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part3:0+118\n",
            "2022-06-27 05:25:15,351 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,351 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,351 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,351 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,351 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,352 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,358 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,358 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,358 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,358 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,358 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,361 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,362 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000012_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,363 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,364 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000012_0' done.\n",
            "2022-06-27 05:25:15,364 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000012_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=302153\n",
            "\t\tFILE: Number of bytes written=924273\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1523056640\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,364 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000012_0\n",
            "2022-06-27 05:25:15,364 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000013_0\n",
            "2022-06-27 05:25:15,365 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,365 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,366 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,366 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part7:0+118\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,432 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,436 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,436 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,436 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,436 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,436 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,437 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,438 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000013_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,440 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,440 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000013_0' done.\n",
            "2022-06-27 05:25:15,440 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000013_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=302816\n",
            "\t\tFILE: Number of bytes written=924333\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1628438528\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,440 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000013_0\n",
            "2022-06-27 05:25:15,440 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000014_0\n",
            "2022-06-27 05:25:15,444 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,445 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,445 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,447 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part8:0+118\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,515 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,520 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,520 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,520 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,520 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,520 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,522 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,523 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000014_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,524 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,524 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000014_0' done.\n",
            "2022-06-27 05:25:15,524 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000014_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=303479\n",
            "\t\tFILE: Number of bytes written=924393\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=127\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1733820416\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,524 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000014_0\n",
            "2022-06-27 05:25:15,524 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_m_000015_0\n",
            "2022-06-27 05:25:15,526 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,526 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,526 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,528 INFO mapred.MapTask: Processing split: file:/content/QuasiMonteCarlo_1656307512552_216270774/in/part13:0+118\n",
            "2022-06-27 05:25:15,592 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-06-27 05:25:15,592 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-06-27 05:25:15,592 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-06-27 05:25:15,592 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,592 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-06-27 05:25:15,593 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-06-27 05:25:15,596 INFO mapred.LocalJobRunner: \n",
            "2022-06-27 05:25:15,596 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-06-27 05:25:15,596 INFO mapred.MapTask: Spilling map output\n",
            "2022-06-27 05:25:15,596 INFO mapred.MapTask: bufstart = 0; bufend = 18; bufvoid = 104857600\n",
            "2022-06-27 05:25:15,596 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2022-06-27 05:25:15,597 INFO mapred.MapTask: Finished spill 0\n",
            "2022-06-27 05:25:15,599 INFO mapred.Task: Task:attempt_local1780158170_0001_m_000015_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,600 INFO mapred.LocalJobRunner: Generated 100000 samples.\n",
            "2022-06-27 05:25:15,600 INFO mapred.Task: Task 'attempt_local1780158170_0001_m_000015_0' done.\n",
            "2022-06-27 05:25:15,600 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_m_000015_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=304142\n",
            "\t\tFILE: Number of bytes written=924453\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=1\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=18\n",
            "\t\tMap output materialized bytes=28\n",
            "\t\tInput split bytes=128\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1839202304\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=130\n",
            "2022-06-27 05:25:15,600 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_m_000015_0\n",
            "2022-06-27 05:25:15,600 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-06-27 05:25:15,617 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-06-27 05:25:15,617 INFO mapred.LocalJobRunner: Starting task: attempt_local1780158170_0001_r_000000_0\n",
            "2022-06-27 05:25:15,630 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-06-27 05:25:15,630 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-06-27 05:25:15,630 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:25:15,634 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b25877d\n",
            "2022-06-27 05:25:15,635 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-06-27 05:25:15,652 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-06-27 05:25:15,656 INFO reduce.EventFetcher: attempt_local1780158170_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-06-27 05:25:15,688 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000014_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,691 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000014_0\n",
            "2022-06-27 05:25:15,691 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->24\n",
            "2022-06-27 05:25:15,693 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000001_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,694 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000001_0\n",
            "2022-06-27 05:25:15,694 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 2, commitMemory -> 24, usedMemory ->48\n",
            "2022-06-27 05:25:15,695 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000007_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,696 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000007_0\n",
            "2022-06-27 05:25:15,696 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 3, commitMemory -> 48, usedMemory ->72\n",
            "2022-06-27 05:25:15,697 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000002_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,702 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000002_0\n",
            "2022-06-27 05:25:15,702 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 4, commitMemory -> 72, usedMemory ->96\n",
            "2022-06-27 05:25:15,703 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000008_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,704 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000008_0\n",
            "2022-06-27 05:25:15,704 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 5, commitMemory -> 96, usedMemory ->120\n",
            "2022-06-27 05:25:15,705 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000006_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,705 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000006_0\n",
            "2022-06-27 05:25:15,705 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 6, commitMemory -> 120, usedMemory ->144\n",
            "2022-06-27 05:25:15,706 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000012_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,707 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000012_0\n",
            "2022-06-27 05:25:15,707 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 7, commitMemory -> 144, usedMemory ->168\n",
            "2022-06-27 05:25:15,708 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000013_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,708 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000013_0\n",
            "2022-06-27 05:25:15,708 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 8, commitMemory -> 168, usedMemory ->192\n",
            "2022-06-27 05:25:15,709 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000000_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,710 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000000_0\n",
            "2022-06-27 05:25:15,710 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 9, commitMemory -> 192, usedMemory ->216\n",
            "2022-06-27 05:25:15,711 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000004_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,713 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000004_0\n",
            "2022-06-27 05:25:15,713 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 10, commitMemory -> 216, usedMemory ->240\n",
            "2022-06-27 05:25:15,716 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000005_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,721 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000005_0\n",
            "2022-06-27 05:25:15,723 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 11, commitMemory -> 240, usedMemory ->264\n",
            "2022-06-27 05:25:15,725 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000011_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,725 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000011_0\n",
            "2022-06-27 05:25:15,725 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 12, commitMemory -> 264, usedMemory ->288\n",
            "2022-06-27 05:25:15,728 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000009_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,729 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000009_0\n",
            "2022-06-27 05:25:15,729 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 13, commitMemory -> 288, usedMemory ->312\n",
            "2022-06-27 05:25:15,730 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000015_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,734 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000015_0\n",
            "2022-06-27 05:25:15,734 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 14, commitMemory -> 312, usedMemory ->336\n",
            "2022-06-27 05:25:15,735 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000010_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,736 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000010_0\n",
            "2022-06-27 05:25:15,738 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 15, commitMemory -> 336, usedMemory ->360\n",
            "2022-06-27 05:25:15,740 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1780158170_0001_m_000003_0 decomp: 24 len: 28 to MEMORY\n",
            "2022-06-27 05:25:15,741 INFO reduce.InMemoryMapOutput: Read 24 bytes from map-output for attempt_local1780158170_0001_m_000003_0\n",
            "2022-06-27 05:25:15,741 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 24, inMemoryMapOutputs.size() -> 16, commitMemory -> 360, usedMemory ->384\n",
            "2022-06-27 05:25:15,741 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-06-27 05:25:15,742 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-06-27 05:25:15,742 INFO reduce.MergeManagerImpl: finalMerge called with 16 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-06-27 05:25:15,752 INFO mapred.Merger: Merging 16 sorted segments\n",
            "2022-06-27 05:25:15,753 INFO mapred.Merger: Down to the last merge-pass, with 16 segments left of total size: 336 bytes\n",
            "2022-06-27 05:25:15,754 INFO reduce.MergeManagerImpl: Merged 16 segments, 384 bytes to disk to satisfy reduce memory limit\n",
            "2022-06-27 05:25:15,754 INFO reduce.MergeManagerImpl: Merging 1 files, 358 bytes from disk\n",
            "2022-06-27 05:25:15,755 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-06-27 05:25:15,755 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-06-27 05:25:15,755 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 351 bytes\n",
            "2022-06-27 05:25:15,756 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-06-27 05:25:15,759 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-06-27 05:25:15,781 INFO mapred.Task: Task:attempt_local1780158170_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-06-27 05:25:15,781 INFO mapred.LocalJobRunner: 16 / 16 copied.\n",
            "2022-06-27 05:25:15,781 INFO mapred.Task: Task attempt_local1780158170_0001_r_000000_0 is allowed to commit now\n",
            "2022-06-27 05:25:15,783 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1780158170_0001_r_000000_0' to file:/content/QuasiMonteCarlo_1656307512552_216270774/out\n",
            "2022-06-27 05:25:15,784 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2022-06-27 05:25:15,784 INFO mapred.Task: Task 'attempt_local1780158170_0001_r_000000_0' done.\n",
            "2022-06-27 05:25:15,785 INFO mapred.Task: Final Counters for attempt_local1780158170_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=305460\n",
            "\t\tFILE: Number of bytes written=925050\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=32\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1839202304\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "2022-06-27 05:25:15,790 INFO mapred.LocalJobRunner: Finishing task: attempt_local1780158170_0001_r_000000_0\n",
            "2022-06-27 05:25:15,790 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-06-27 05:25:15,927 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-06-27 05:25:15,927 INFO mapreduce.Job: Job job_local1780158170_0001 completed successfully\n",
            "2022-06-27 05:25:15,942 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=5040972\n",
            "\t\tFILE: Number of bytes written=15709098\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=16\n",
            "\t\tMap output records=32\n",
            "\t\tMap output bytes=288\n",
            "\t\tMap output materialized bytes=448\n",
            "\t\tInput split bytes=2038\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=448\n",
            "\t\tReduce input records=32\n",
            "\t\tReduce output records=0\n",
            "\t\tSpilled Records=64\n",
            "\t\tShuffled Maps =16\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=16\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=18620612608\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=2080\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=109\n",
            "Job Finished in 2.786 seconds\n",
            "Estimated value of Pi is 3.14157500000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHwLU0Uo3tLo"
      },
      "source": [
        "#Install HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bODP1xaM3vEB",
        "outputId": "2b4ff7a7-b9b1-40bb-fe1a-a1e9ac02e032"
      },
      "source": [
        "# Get the latest HBase download site from here https://www.apache.org/dyn/closer.lua/hbase/\n",
        "#!wget https://mirrors.estointernet.in/apache/hbase/2.4.5/hbase-2.4.5-bin.tar.gz\n",
        "#!wget https://mirrors.estointernet.in/apache/hbase/2.4.8/hbase-2.4.8-bin.tar.gz\n",
        "#!wget https://downloads.apache.org/hbase/2.4.9/hbase-2.4.9-bin.tar.gz\n",
        "!wget https://downloads.apache.org/hbase/2.4.12/hbase-2.4.12-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.5-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.8-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.9-bin.tar.gz\n",
        "!tar xzf hbase-2.4.12-bin.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 05:25:56--  https://downloads.apache.org/hbase/2.4.12/hbase-2.4.12-bin.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 283605397 (270M) [application/x-gzip]\n",
            "Saving to: ‘hbase-2.4.12-bin.tar.gz’\n",
            "\n",
            "hbase-2.4.12-bin.ta 100%[===================>] 270.47M  25.4MB/s    in 11s     \n",
            "\n",
            "2022-06-27 05:26:08 (23.7 MB/s) - ‘hbase-2.4.12-bin.tar.gz’ saved [283605397/283605397]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaMtyNOVCiMS"
      },
      "source": [
        "## Set HBase Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4dc0K7h4f-y",
        "outputId": "8725257b-ef73-4e69-cba5-eb31e18e7666"
      },
      "source": [
        "#os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "#!echo $HIVE_HOME\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.5/\"\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.8/\"\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.9/\"\n",
        "os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.12/\"\n",
        "!echo $HBASE_HOME\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hbase-2.4.12/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXZ_kF65VXK",
        "outputId": "f6d7e016-4d49-464a-cc83-4dd2afeee427"
      },
      "source": [
        "# current_path taken from command in previous cell\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "#new_path = current_path+':/content/hbase-2.4.5/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/content/hbase-2.4.8/bin'\n",
        "#new_path = current_path+':/content/hbase-2.4.9/bin'\n",
        "new_path = current_path+':/content/hbase-2.4.12/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.3/bin/:/content/hbase-2.4.12/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrS6BL5k51Bl",
        "outputId": "d3640838-e12a-4955-b53b-a2933ac38a59"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HBASE_HOME"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.3/\n",
            "/content/hbase-2.4.12/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kDmgFfh6a12"
      },
      "source": [
        "# the file hbase-site.xml may need to be updated ...\n",
        "# however the default file works well in the simple stand-alone HBase mode\n",
        "# so no need to touch it\n",
        "#!cat $HBASE_HOME/conf/hbase-site.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWn-DJ1PDbXd"
      },
      "source": [
        "## Some Clean UP\n",
        "Otherwise we get ugly warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKG7t8sQDj2t",
        "outputId": "018e392b-a3c3-4aa5-8fbe-733c5d05ef3d"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HBASE_HOME/lib/*slf4j*\n",
        "!ls /content/hbase-2.4.12/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/slf4j-api-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar\n",
            "/content/hbase-2.4.12//lib/jcl-over-slf4j-1.7.33.jar\n",
            "/content/hbase-2.4.12//lib/jul-to-slf4j-1.7.33.jar\n",
            "/content/hbase-2.4.12/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaOkjD5EOr0"
      },
      "source": [
        "# remove the Hadoop logger out of the path\n",
        "# without this you will get ugly warnings every time\n",
        "#!mv /usr/local/hadoop-3.3.0//share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar .\n",
        "!mv /content/hbase-2.4.12/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar ."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA03iA4XFN_E"
      },
      "source": [
        "## Start HBase server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMQHzlCO7MDC",
        "outputId": "9108b6de-07ab-4495-f2f1-f5e4fc041c23"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.12//logs/hbase--master-d1d969b050f0.out\n",
            "1426 HMaster\n",
            "1582 Jps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6mdgPSFSvB"
      },
      "source": [
        "# Run Hbase Shell\n",
        "do not skip these two shell commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42DJQfpY7oqe"
      },
      "source": [
        "# you can enter hbase shell commands at the prompt. Double click on the prompt to open up a input box\n",
        "#!hbase shell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhuHJF4lH6f6"
      },
      "source": [
        "shell commands  <br>\n",
        "https://www.tutorialspoint.com/hbase/hbase_shell.htm <br>\n",
        "https://www.guru99.com/hbase-shell-general-commands.html <br>\n",
        "better way of passing shell commands are given here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdbisL2GQtE",
        "outputId": "7fff3550-0e97-4c9f-c73f-3c1873a598cf"
      },
      "source": [
        "!echo 'status' | hbase shell -n\n",
        "#!echo \"status 'detail'\" | hbase shell -n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hbase:001:0> status\n",
            "1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load\n",
            "Took 0.6363 seconds                                                             \n",
            "hbase:002:0> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYhR2DpgIbnU",
        "outputId": "22709434-e603-4fc5-8f13-fbd21e471bf8"
      },
      "source": [
        "!echo \"whoami\" | hbase shell -n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hbase:001:0> whoami\n",
            "root (auth:SIMPLE)\n",
            "    groups: root\n",
            "Took 0.0152 seconds                                                             \n",
            "hbase:002:0> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMwSSDZd6T9"
      },
      "source": [
        "#Install HappyBase / Thrift <br>\n",
        "https://happybase.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qOwqJlQfQLc",
        "outputId": "5694918c-3e15-4bc1-bd37-f71a40158829"
      },
      "source": [
        "!stop-hbase.sh"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase..............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLfCN8jpZsZH",
        "outputId": "30cc5e54-87f6-4bbe-cc58-ab0eae52a7d3"
      },
      "source": [
        "!pip -qq install happybase"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 40 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 361 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s \n",
            "\u001b[?25h  Building wheel for happybase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Wt2asZZb3m"
      },
      "source": [
        "import happybase\n",
        "#https://happybase.readthedocs.io/en/latest/"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-OVMxNEaWOq",
        "outputId": "69a7cd7c-9630-4dd2-ae41-da818e44e5f2"
      },
      "source": [
        "#!ls hbase-2.4.8/bin\n",
        "#!hbase-2.4.8/bin/hbase-daemon.sh start thrift\n",
        "!hbase-daemon.sh start thrift"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running thrift, logging to /content/hbase-2.4.12//logs/hbase--thrift-d1d969b050f0.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHyIyGFf0yl",
        "outputId": "9af712f3-3d31-441e-e6b6-24d9f7c7f485"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.12//logs/hbase--master-d1d969b050f0.out\n",
            "3289 Jps\n",
            "2767 ThriftServer\n",
            "3135 HMaster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uL64b823-CB"
      },
      "source": [
        "#connection = happybase.Connection('localhost',9090, transport='framed',protocol='compact')\n",
        "#if this connection suddenly closes, you may get errors. in that case, re-run this cell again\n",
        "kxn = happybase.Connection('localhost',9090,autoconnect=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4yg79ueMhYZ"
      },
      "source": [
        "#Create Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFjctMtoeCcW",
        "outputId": "a78c78f4-f4dc-4932-abcb-24224cab6d97"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvAuebzbXj6"
      },
      "source": [
        "##Create Dept Table, Insert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiUqgnVCMcl3"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Dept')\n",
        "#kxn.delete_table('Dept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Dept',\n",
        "    {'DeptID': dict(max_versions=10),              # these are column families, which can take different columns\n",
        "     'DeptName': dict(max_versions=1, block_cache_enabled=False),\n",
        "     'ManagerID': dict(),  # use defaults\n",
        "     'Location': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsULtvF6Nfcx"
      },
      "source": [
        "kxn.open()\n",
        "tDept = kxn.table('Dept')\n",
        "kxn.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jju96MNoCf"
      },
      "source": [
        "#Insert one row\n",
        "kxn.open()\n",
        "tDept.put('10',{'DeptName:': 'Corporate', 'ManagerID:': '123456','Location:':'Calcutta'})\n",
        "kxn.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP5nd0nIOTxf",
        "outputId": "8c36c5ea-c95f-422e-b5ea-865cf1790632"
      },
      "source": [
        "kxn.open()\n",
        "for key, data in tDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Y9zgCJOywZ"
      },
      "source": [
        "#Insert 3 more rows in Batch\n",
        "kxn.open()\n",
        "b = tDept.batch()\n",
        "b.put(b'20', { b'DeptName:': b'Sales', b'ManagerID:': b'234567', b'Location:': b'Calcutta'})\n",
        "b.put(b'30', { b'DeptName:': b'Accounts', b'ManagerID:': b'567234', b'Location:': b'Calcutta'})\n",
        "b.put(b'40', { b'DeptName:': b'Production', b'ManagerID:': b'345876', b'Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn9puFvNSQ0I",
        "outputId": "30716110-aff0-4961-b288-c0e5fedeeb11"
      },
      "source": [
        "#show all four ROWS\n",
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, value in tDept.scan():\n",
        "    print(key, value)\n",
        "kxn.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n",
            "b'20' {b'DeptName:': b'Sales', b'Location:': b'Calcutta', b'ManagerID:': b'234567'}\n",
            "b'30' {b'DeptName:': b'Accounts', b'Location:': b'Calcutta', b'ManagerID:': b'567234'}\n",
            "b'40' {b'DeptName:': b'Production', b'Location:': b'Bombay', b'ManagerID:': b'345876'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjTzUYObi7W"
      },
      "source": [
        "##Create Emp Table, LOAD data <br>\n",
        "https://people.apache.org/~stack/site/bulk-loads.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GbQWvRcTwu"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Emp')\n",
        "#kxn.delete_table('Emp')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Emp',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'LastName': dict(),  # use defaults\n",
        "     'FirstName': dict(),  # use defaults\n",
        "     'Role': dict(),  # use defaults\n",
        "     'DoJ': dict(),  # use defaults\n",
        "     'Salary': dict(),  # use defaults\n",
        "     'Comm': dict(),  # use defaults\n",
        "     'DeptID': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XDyx1HQxBL",
        "outputId": "fa7bf42f-ee5d-4a3e-8c2c-8cbd28e2cdbc"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYH_g_J6423R"
      },
      "source": [
        "#Download txt file with Employee Data\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/Employee.csv"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cat Employee.csv"
      ],
      "metadata": {
        "id": "Hmd38X4s1bmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe13297-e16d-40df-de00-3abe4cfcdf0d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "742866,Bacchan,Amitabh,Executive,2003-03-10,50000,0.1,10\n",
            "349870,Mukherjee,Rani,Manager,2005-05-04,25000,0.06,40\n",
            "865477,Dikshit,Madhuri,Clerk,2002-04-04,10000,0.02,20\n",
            "239456,Khan,Shahrukh,Manager,2004-01-03,30000,0.07,20\n",
            "897889,Sehwag,Virender,Cus_Rep,2005-01-02,15000,0.05,20\n",
            "123980,Dhoni,Mahender,Clerk,2004-10-09,9000,0.02,40\n",
            "822134,Dravid,Rahul,Sr Manager,2000-06-04,40000,0.08,30\n",
            "997445,Dalmia,Jagmohan,Clerk,2001-07-01,12000,0.02,30\n",
            "989007,Ganguly,Sourav,Cus_Rep,2002-01-01,20000,0.03,40\n",
            "299034,Ganesan,Rekha,Director,2002-10-10,60000,0.11,10\n",
            "546223,Karthikeyan,Narayan,Secretary,2005-12-04,40000,0.09,10\n",
            "223112,Mirza,Sania,Cus_Rep,2001-11-19,25000,0.04,30"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZbsNgyBd-aN"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal Employee.csv /tmp"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRp3yateTCS",
        "outputId": "4d64ec7c-80d0-4604-fe00-7baacee6236d"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,LastName:,FirstName:,Role:,DoJ:,Salary:,Comm:,DeptID:\" Emp /tmp/Employee.csv"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-27 05:50:51,400 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:host.name=d1d969b050f0\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_312\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.vendor=Private Build\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: op/yarn/hadoop-yarn-applications-distributedshell-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-tests-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-services-api-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-common-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-registry-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-common-3.3.3.jar\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop-3.3.3//lib/native\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.name=Linux\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.arch=amd64\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.version=5.4.188+\n",
            "2022-06-27 05:50:51,401 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.name=root\n",
            "2022-06-27 05:50:51,402 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.home=/root\n",
            "2022-06-27 05:50:51,402 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.dir=/content\n",
            "2022-06-27 05:50:51,402 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.free=178MB\n",
            "2022-06-27 05:50:51,402 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.max=3231MB\n",
            "2022-06-27 05:50:51,402 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.total=197MB\n",
            "2022-06-27 05:50:51,406 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 05:50:51,411 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] common.X509Util: Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation\n",
            "2022-06-27 05:50:51,418 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 05:50:51,426 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 05:50:51,435 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 05:50:51,440 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:47254, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 05:50:51,448 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f4000007, negotiated timeout = 40000\n",
            "2022-06-27 05:50:52,930 INFO  [main] Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2022-06-27 05:50:52,933 INFO  [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2022-06-27 05:50:52,988 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 05:50:52,989 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 05:50:52,989 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 05:50:52,990 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 05:50:52,990 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:47276, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 05:50:52,994 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f4000008, negotiated timeout = 40000\n",
            "2022-06-27 05:50:53,003 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Session: 0x1000012f4000007 closed\n",
            "2022-06-27 05:50:53,003 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f4000007\n",
            "2022-06-27 05:50:53,125 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ZooKeeper: Session: 0x1000012f4000008 closed\n",
            "2022-06-27 05:50:53,125 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f4000008\n",
            "2022-06-27 05:50:53,190 INFO  [main] input.FileInputFormat: Total input files to process : 1\n",
            "2022-06-27 05:50:53,246 INFO  [main] mapreduce.JobSubmitter: number of splits:1\n",
            "2022-06-27 05:50:53,515 INFO  [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1577055068_0001\n",
            "2022-06-27 05:50:53,921 INFO  [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/1656309053703/libjars <- /content/libjars/*\n",
            "2022-06-27 05:50:53,929 WARN  [main] fs.FileUtil: Command 'ln -s /tmp/hadoop-root/mapred/local/1656309053703/libjars /content/libjars/*' failed 1 with: ln: failed to create symbolic link '/content/libjars/*': No such file or directory\n",
            "\n",
            "2022-06-27 05:50:53,929 WARN  [main] mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-root/mapred/local/1656309053703/libjars <- /content/libjars/*\n",
            "2022-06-27 05:50:53,929 INFO  [main] mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop-root/mapred/staging/root1577055068/.staging/job_local1577055068_0001/libjars as file:/tmp/hadoop-root/mapred/local/1656309053703/libjars\n",
            "2022-06-27 05:50:54,003 INFO  [main] mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-06-27 05:50:54,004 INFO  [main] mapreduce.Job: Running job: job_local1577055068_0001\n",
            "2022-06-27 05:50:54,011 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-06-27 05:50:54,036 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hbase.mapreduce.TableOutputCommitter\n",
            "2022-06-27 05:50:54,065 INFO  [Thread-7] mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-06-27 05:50:54,066 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1577055068_0001_m_000000_0\n",
            "2022-06-27 05:50:54,148 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 05:50:54,158 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/tmp/Employee.csv:0+661\n",
            "2022-06-27 05:50:54,167 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 05:50:54,167 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 05:50:54,168 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 05:50:54,168 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 05:50:54,169 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:47288, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 05:50:54,172 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f4000009, negotiated timeout = 40000\n",
            "2022-06-27 05:50:54,178 INFO  [LocalJobRunner Map Task Executor #0] mapreduce.TableOutputFormat: Created table instance for Emp\n",
            "2022-06-27 05:50:54,212 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 05:50:54,212 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 05:50:54,212 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 05:50:54,213 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 05:50:54,213 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:47290, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 05:50:54,221 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f400000a, negotiated timeout = 40000\n",
            "2022-06-27 05:50:54,303 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: \n",
            "2022-06-27 05:50:54,387 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1577055068_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-06-27 05:50:54,398 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05] zookeeper.ZooKeeper: Session: 0x1000012f400000a closed\n",
            "2022-06-27 05:50:54,398 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x7db95d05-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f400000a\n",
            "2022-06-27 05:50:54,404 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map\n",
            "2022-06-27 05:50:54,404 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1577055068_0001_m_000000_0' done.\n",
            "2022-06-27 05:50:54,412 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1577055068_0001_m_000000_0: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=432722\n",
            "\t\tFILE: Number of bytes written=1005110\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=87\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=320\n",
            "\t\tPhysical memory (bytes) snapshot=276180992\n",
            "\t\tVirtual memory (bytes) snapshot=5155586048\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=685\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n",
            "2022-06-27 05:50:54,413 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1577055068_0001_m_000000_0\n",
            "2022-06-27 05:50:54,413 INFO  [Thread-7] mapred.LocalJobRunner: map task executor complete.\n",
            "2022-06-27 05:50:54,494 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b] zookeeper.ZooKeeper: Session: 0x1000012f4000009 closed\n",
            "2022-06-27 05:50:54,494 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x34031c3b-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f4000009\n",
            "2022-06-27 05:50:55,009 INFO  [main] mapreduce.Job: Job job_local1577055068_0001 running in uber mode : false\n",
            "2022-06-27 05:50:55,010 INFO  [main] mapreduce.Job:  map 100% reduce 0%\n",
            "2022-06-27 05:50:55,014 INFO  [main] mapreduce.Job: Job job_local1577055068_0001 completed successfully\n",
            "2022-06-27 05:50:55,022 INFO  [main] mapreduce.Job: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=432722\n",
            "\t\tFILE: Number of bytes written=1005110\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=87\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=320\n",
            "\t\tPhysical memory (bytes) snapshot=276180992\n",
            "\t\tVirtual memory (bytes) snapshot=5155586048\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=685\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxvMPuZ8gOW5"
      },
      "source": [
        "kxn.open()\n",
        "tEmp = kxn.table('Emp')\n",
        "kxn.close()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uonqOE2AgXeq",
        "outputId": "28cdbafa-9845-4817-a248-46316e3d0130"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmp.scan(): \n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Comm:': b'0.02', b'DeptID:': b'40', b'DoJ:': b'2004-10-09', b'FirstName:': b'Mahender', b'LastName:': b'Dhoni', b'Role:': b'Clerk', b'Salary:': b'9000'}\n",
            "b'223112' {b'Comm:': b'0.04', b'DeptID:': b'30', b'DoJ:': b'2001-11-19', b'FirstName:': b'Sania', b'LastName:': b'Mirza', b'Role:': b'Cus_Rep', b'Salary:': b'25000'}\n",
            "b'239456' {b'Comm:': b'0.07', b'DeptID:': b'20', b'DoJ:': b'2004-01-03', b'FirstName:': b'Shahrukh', b'LastName:': b'Khan', b'Role:': b'Manager', b'Salary:': b'30000'}\n",
            "b'299034' {b'Comm:': b'0.11', b'DeptID:': b'10', b'DoJ:': b'2002-10-10', b'FirstName:': b'Rekha', b'LastName:': b'Ganesan', b'Role:': b'Director', b'Salary:': b'60000'}\n",
            "b'349870' {b'Comm:': b'0.06', b'DeptID:': b'40', b'DoJ:': b'2005-05-04', b'FirstName:': b'Rani', b'LastName:': b'Mukherjee', b'Role:': b'Manager', b'Salary:': b'25000'}\n",
            "b'546223' {b'Comm:': b'0.09', b'DeptID:': b'10', b'DoJ:': b'2005-12-04', b'FirstName:': b'Narayan', b'LastName:': b'Karthikeyan', b'Role:': b'Secretary', b'Salary:': b'40000'}\n",
            "b'742866' {b'Comm:': b'0.1', b'DeptID:': b'10', b'DoJ:': b'2003-03-10', b'FirstName:': b'Amitabh', b'LastName:': b'Bacchan', b'Role:': b'Executive', b'Salary:': b'50000'}\n",
            "b'822134' {b'Comm:': b'0.08', b'DeptID:': b'30', b'DoJ:': b'2000-06-04', b'FirstName:': b'Rahul', b'LastName:': b'Dravid', b'Role:': b'Sr Manager', b'Salary:': b'40000'}\n",
            "b'865477' {b'Comm:': b'0.02', b'DeptID:': b'20', b'DoJ:': b'2002-04-04', b'FirstName:': b'Madhuri', b'LastName:': b'Dikshit', b'Role:': b'Clerk', b'Salary:': b'10000'}\n",
            "b'897889' {b'Comm:': b'0.05', b'DeptID:': b'20', b'DoJ:': b'2005-01-02', b'FirstName:': b'Virender', b'LastName:': b'Sehwag', b'Role:': b'Cus_Rep', b'Salary:': b'15000'}\n",
            "b'989007' {b'Comm:': b'0.03', b'DeptID:': b'40', b'DoJ:': b'2002-01-01', b'FirstName:': b'Sourav', b'LastName:': b'Ganguly', b'Role:': b'Cus_Rep', b'Salary:': b'20000'}\n",
            "b'997445' {b'Comm:': b'0.02', b'DeptID:': b'30', b'DoJ:': b'2001-07-01', b'FirstName:': b'Jagmohan', b'LastName:': b'Dalmia', b'Role:': b'Clerk', b'Salary:': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS__XdMYjLzd"
      },
      "source": [
        "## Creating, INSERTing Denormalised EmpDept Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQRpLsmfjbgp"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('EmpDept')\n",
        "#kxn.delete_table('EmpDept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6Zk4bKqMas",
        "outputId": "e5d0647c-b1d4-4b08-bd99-5bf1ee0d12a4"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duGwwpF1n5IG"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept = kxn.table('EmpDept')\n",
        "b = tEmpDept.batch()\n",
        "b.put(b'742866', { b'Emp:FirstName': b'Amitabh', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta'}) #742866-emp id, emp-column family, firstname-column \n",
        "b.put(b'349870', { b'Emp:LastName': b'Mukheree', b'Dept:ManagerID': b'567234', b'Dept:Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzxFRXp7rS87",
        "outputId": "45d65230-5829-42bc-9dca-98b39b6389b5"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmpDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'349870' {b'Dept:Location:': b'Bombay', b'Dept:ManagerID': b'567234', b'Emp:LastName': b'Mukheree'}\n",
            "b'742866' {b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Emp:FirstName': b'Amitabh'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWZKpJ_LtMnQ"
      },
      "source": [
        "##Creating and LOADing denormalised tables EmpDept2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giAKNFnMtJ-b"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('EmpDept2')\n",
        "#kxn.delete_table('EmpDept2')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept2',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WwCA4euf-i",
        "outputId": "e851fb7c-2e66-4c95-feca-c9930b7aea1e"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept', b'EmpDept2']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fijaJ_G5ktF"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/EmployeeDept2.txt"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat EmployeeDept2.txt"
      ],
      "metadata": {
        "id": "319EWjdEB5yn",
        "outputId": "53a53cec-c66c-4d6a-9483-09ab639d097d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "742866,Bacchan,Amitabh,Executive,2003-03-10,50000,0.1,10,Corporate,299034,Calcutta\n",
            "349870,Mukherjee,Rani,Manager,2005-05-04,25000,0.06,40,Production,349870,Bombay\n",
            "865477,Dikshit,Madhuri,Clerk,2002-04-04,10000,0.02,20,Sales,239456,Calcutta\n",
            "239456,Khan,Shahrukh,Manager,2004-01-03,30000,0.07,20,Sales,239456,Calcutta\n",
            "897889,Sehwag,Virender,Cus_Rep,2005-01-02,15000,0.05,20,Sales,239456,Calcutta\n",
            "123980,Dhoni,Mahender,Clerk,2004-10-09,9000,0.02,40,Production,349870,Bombay\n",
            "822134,Dravid,Rahul,Sr Manager,2000-06-04,40000,0.08,30,Accounts,822134,Calcutta\n",
            "997445,Dalmia,Jagmohan,Clerk,2001-07-01,12000,0.02,30,Accounts,822134,Calcutta\n",
            "989007,Ganguly,Sourav,Cus_Rep,2002-01-01,20000,0.03,40,Production,349870,Bombay\n",
            "299034,Ganesan,Rekha,Director,2002-10-10,60000,0.11,10,Corporate,299034,Calcutta\n",
            "546223,Karthikeyan,Narayan,Secretary,2005-12-04,40000,0.09,10,Corporate,299034,Calcutta\n",
            "223112,Mirza,Sania,Cus_Rep,2001-11-19,25000,0.04,30,Accounts,822134,Calcutta"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvItjBLuu7oM"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal EmployeeDept2.txt /tmp"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_VFWQZJvXqn",
        "outputId": "ec8dceec-d5e7-4f3f-e536-b94185ffc710"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,Emp:LastName,Emp:FirstName,Emp:Role,Emp:DoJ,Emp:Salary,Emp:Comm,Dept:DeptID,Dept:DeptName,Dept:ManagerID,Dept:Location\" EmpDept2 /tmp/EmployeeDept2.txt"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-27 06:04:43,498 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:host.name=d1d969b050f0\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_312\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.vendor=Private Build\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: op/yarn/hadoop-yarn-applications-distributedshell-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-tests-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-services-api-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-common-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-registry-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.3.jar:/usr/local/hadoop-3.3.3//share/hadoop/yarn/hadoop-yarn-server-common-3.3.3.jar\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop-3.3.3//lib/native\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n",
            "2022-06-27 06:04:43,499 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.name=Linux\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.arch=amd64\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.version=5.4.188+\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.name=root\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.home=/root\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:user.dir=/content\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.free=178MB\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.max=3231MB\n",
            "2022-06-27 06:04:43,500 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Client environment:os.memory.total=197MB\n",
            "2022-06-27 06:04:43,504 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 06:04:43,512 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] common.X509Util: Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation\n",
            "2022-06-27 06:04:43,520 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 06:04:43,529 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 06:04:43,546 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 06:04:43,553 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:49294, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 06:04:43,563 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f400000b, negotiated timeout = 40000\n",
            "2022-06-27 06:04:44,942 INFO  [main] Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2022-06-27 06:04:44,943 INFO  [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2022-06-27 06:04:45,001 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091] zookeeper.ZooKeeper: Session: 0x1000012f400000b closed\n",
            "2022-06-27 06:04:45,003 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x1ce24091-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f400000b\n",
            "2022-06-27 06:04:45,088 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 06:04:45,089 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 06:04:45,091 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 06:04:45,099 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 06:04:45,100 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:49304, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 06:04:45,103 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f400000c, negotiated timeout = 40000\n",
            "2022-06-27 06:04:45,230 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18] zookeeper.ZooKeeper: Session: 0x1000012f400000c closed\n",
            "2022-06-27 06:04:45,230 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5ddabb18-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f400000c\n",
            "2022-06-27 06:04:45,348 INFO  [main] input.FileInputFormat: Total input files to process : 1\n",
            "2022-06-27 06:04:45,377 INFO  [main] mapreduce.JobSubmitter: number of splits:1\n",
            "2022-06-27 06:04:45,546 INFO  [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1695536428_0001\n",
            "2022-06-27 06:04:45,797 INFO  [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/1656309885638/libjars <- /content/libjars/*\n",
            "2022-06-27 06:04:45,805 WARN  [main] fs.FileUtil: Command 'ln -s /tmp/hadoop-root/mapred/local/1656309885638/libjars /content/libjars/*' failed 1 with: ln: failed to create symbolic link '/content/libjars/*': No such file or directory\n",
            "\n",
            "2022-06-27 06:04:45,805 WARN  [main] mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-root/mapred/local/1656309885638/libjars <- /content/libjars/*\n",
            "2022-06-27 06:04:45,805 INFO  [main] mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop-root/mapred/staging/root1695536428/.staging/job_local1695536428_0001/libjars as file:/tmp/hadoop-root/mapred/local/1656309885638/libjars\n",
            "2022-06-27 06:04:45,891 INFO  [main] mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-06-27 06:04:45,892 INFO  [main] mapreduce.Job: Running job: job_local1695536428_0001\n",
            "2022-06-27 06:04:45,897 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-06-27 06:04:45,924 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hbase.mapreduce.TableOutputCommitter\n",
            "2022-06-27 06:04:45,955 INFO  [Thread-7] mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-06-27 06:04:45,956 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1695536428_0001_m_000000_0\n",
            "2022-06-27 06:04:46,015 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-06-27 06:04:46,027 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/tmp/EmployeeDept2.txt:0+955\n",
            "2022-06-27 06:04:46,040 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 06:04:46,040 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 06:04:46,040 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 06:04:46,041 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 06:04:46,042 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:49310, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 06:04:46,045 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f400000d, negotiated timeout = 40000\n",
            "2022-06-27 06:04:46,051 INFO  [LocalJobRunner Map Task Executor #0] mapreduce.TableOutputFormat: Created table instance for EmpDept2\n",
            "2022-06-27 06:04:46,093 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/895446950@3ac1a97a\n",
            "2022-06-27 06:04:46,094 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2022-06-27 06:04:46,094 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2022-06-27 06:04:46,095 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2022-06-27 06:04:46,096 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:49312, server: localhost/127.0.0.1:2181\n",
            "2022-06-27 06:04:46,101 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000012f400000e, negotiated timeout = 40000\n",
            "2022-06-27 06:04:46,173 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: \n",
            "2022-06-27 06:04:46,269 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1] zookeeper.ZooKeeper: Session: 0x1000012f400000e closed\n",
            "2022-06-27 06:04:46,269 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x388821d1-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f400000e\n",
            "2022-06-27 06:04:46,360 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1695536428_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-06-27 06:04:46,387 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map\n",
            "2022-06-27 06:04:46,387 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1695536428_0001_m_000000_0' done.\n",
            "2022-06-27 06:04:46,395 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1695536428_0001_m_000000_0: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=433021\n",
            "\t\tFILE: Number of bytes written=1005275\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=92\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=350\n",
            "\t\tPhysical memory (bytes) snapshot=273248256\n",
            "\t\tVirtual memory (bytes) snapshot=5149696000\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=979\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n",
            "2022-06-27 06:04:46,395 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1695536428_0001_m_000000_0\n",
            "2022-06-27 06:04:46,395 INFO  [Thread-7] mapred.LocalJobRunner: map task executor complete.\n",
            "2022-06-27 06:04:46,465 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092] zookeeper.ZooKeeper: Session: 0x1000012f400000d closed\n",
            "2022-06-27 06:04:46,465 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x5b297092-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x1000012f400000d\n",
            "2022-06-27 06:04:46,896 INFO  [main] mapreduce.Job: Job job_local1695536428_0001 running in uber mode : false\n",
            "2022-06-27 06:04:46,897 INFO  [main] mapreduce.Job:  map 100% reduce 0%\n",
            "2022-06-27 06:04:46,899 INFO  [main] mapreduce.Job: Job job_local1695536428_0001 completed successfully\n",
            "2022-06-27 06:04:46,908 INFO  [main] mapreduce.Job: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=433021\n",
            "\t\tFILE: Number of bytes written=1005275\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=92\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=350\n",
            "\t\tPhysical memory (bytes) snapshot=273248256\n",
            "\t\tVirtual memory (bytes) snapshot=5149696000\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=979\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-H5Zh5UwRzd"
      },
      "source": [
        "tEmpDept2 = kxn.table('EmpDept2')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4tQppiqwMTk",
        "outputId": "18fc6c68-b698-4486-d262-a39d7aa3df5f"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n",
            "b'223112' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.04', b'Emp:DoJ': b'2001-11-19', b'Emp:FirstName': b'Sania', b'Emp:LastName': b'Mirza', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'25000'}\n",
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n",
            "b'989007' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.03', b'Emp:DoJ': b'2002-01-01', b'Emp:FirstName': b'Sourav', b'Emp:LastName': b'Ganguly', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'20000'}\n",
            "b'997445' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2001-07-01', b'Emp:FirstName': b'Jagmohan', b'Emp:LastName': b'Dalmia', b'Emp:Role': b'Clerk', b'Emp:Salary': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIY0y-OO1rV"
      },
      "source": [
        "#Data Retrieval <br>\n",
        "https://happybase.readthedocs.io/en/latest/user.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmYXOCEO-EJ",
        "outputId": "56b2658d-c53a-44f5-acfa-5ff2e03dd72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive One Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "prow = tEmpDept2.row(b'123980')\n",
        "print(prow)   # prints the value of cf1:col1"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azcfxg2YP9AH",
        "outputId": "af1b0111-9728-4634-bd5c-e8272fe3d8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "listOfrows = [b'742866', b'897889']\n",
        "rows = tEmpDept2.rows(listOfrows)\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69-NH_HcQ84G",
        "outputId": "0b5c9b6e-d7e2-4e1e-a049-9295ee194f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rowsDict = dict(tEmpDept2.rows([b'742866', b'897889']))\n",
        "for k,v in rowsDict.items():\n",
        "    print(k,v)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25jvHL81TwcN",
        "outputId": "879becd9-7f1b-4819-b8d0-b0de7244cbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Emp'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT0svpwPUOUo",
        "outputId": "e3c7887c-ed3c-417f-c99b-abfb5278656e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Dept'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxjJtKhrUWwM",
        "outputId": "8e995027-1053-4289-e84b-04385c8565a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Emp:LastName',b'Dept:Location'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Bacchan'}\n",
            "b'897889' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Sehwag'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQs2EH6OU74d",
        "outputId": "65e0602e-09bc-42fd-fb9d-4119539a7895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n",
            "b'223112' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.04', b'Emp:DoJ': b'2001-11-19', b'Emp:FirstName': b'Sania', b'Emp:LastName': b'Mirza', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'25000'}\n",
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n",
            "b'989007' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.03', b'Emp:DoJ': b'2002-01-01', b'Emp:FirstName': b'Sourav', b'Emp:LastName': b'Ganguly', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'20000'}\n",
            "b'997445' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2001-07-01', b'Emp:FirstName': b'Jagmohan', b'Emp:LastName': b'Dalmia', b'Emp:Role': b'Clerk', b'Emp:Salary': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2Qhg60VEtX",
        "outputId": "0ef9c048-4331-4109-cf21-4f9ccbe204c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan(row_start=b'230000', row_stop=b'870000'):\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXl-QezFVXSS",
        "outputId": "5d3c220b-79d0-4cc6-c22a-f85c9f540c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#kxn = happybase.Connection('localhost',9090,autoconnect=False)\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan(row_start=b'230000', row_stop=b'870000',columns=[b'Emp:LastName',b'Dept:Location']):\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'239456' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Khan'}\n",
            "b'299034' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Ganesan'}\n",
            "b'349870' {b'Dept:Location': b'Bombay', b'Emp:LastName': b'Mukherjee'}\n",
            "b'546223' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Karthikeyan'}\n",
            "b'742866' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Bacchan'}\n",
            "b'822134' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Dravid'}\n",
            "b'865477' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Dikshit'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PP3akdlVKJ"
      },
      "source": [
        "#Stop HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p28XBoitAWTL",
        "outputId": "7ffbb928-6602-44d0-a91f-cf6e3bac8fa6"
      },
      "source": [
        "!stop-hbase.sh"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase...........\n"
          ]
        }
      ]
    }
  ]
}