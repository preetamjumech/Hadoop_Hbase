{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/Hadoop_Hbase_practice/blob/main/Preetam_Saha_B3A_Hadoop_HBase_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYTQEpb1htS"
      },
      "source": [
        "#Hadoop \n",
        "Install and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0IOmlc0-Dt"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWspfH6A1a4P",
        "outputId": "2d2e937c-0795-430d-afed-ff50f0f075e8"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "#!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.3/hadoop-3.3.3.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "#!tar -xzf hadoop-3.3.0.tar.gz\n",
        "!tar -xzf hadoop-3.3.3.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "#!mv  hadoop-3.3.0/ /usr/local/\n",
        "!mv  hadoop-3.3.3/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-07 06:41:31--  https://downloads.apache.org/hadoop/common/hadoop-3.3.3/hadoop-3.3.3.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 645040598 (615M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.3.tar.gz’\n",
            "\n",
            "hadoop-3.3.3.tar.gz 100%[===================>] 615.16M  17.3MB/s    in 34s     \n",
            "\n",
            "2022-11-07 06:42:06 (17.9 MB/s) - ‘hadoop-3.3.3.tar.gz’ saved [645040598/645040598]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24QjQ22V1swJ"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugibq3m1CbgC"
      },
      "source": [
        "## Set Hadoop Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7WFh5k18E1"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "#os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.0/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.3/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaaMpfVP2p3m"
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# current_path taken from last command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.3/bin/'\n",
        "os.environ[\"PATH\"] = new_path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD34gT3y2u-D"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000\n",
        "!hadoop jar /usr/local/hadoop-3.3.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.3.jar pi 16 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHwLU0Uo3tLo"
      },
      "source": [
        "#Install HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bODP1xaM3vEB",
        "outputId": "057116c3-858d-4d72-8441-cd4dcdc60333"
      },
      "source": [
        "# Get the latest HBase download site from here https://www.apache.org/dyn/closer.lua/hbase/\n",
        "#!wget https://mirrors.estointernet.in/apache/hbase/2.4.5/hbase-2.4.5-bin.tar.gz\n",
        "#!wget https://mirrors.estointernet.in/apache/hbase/2.4.8/hbase-2.4.8-bin.tar.gz\n",
        "#!wget https://downloads.apache.org/hbase/2.4.9/hbase-2.4.9-bin.tar.gz\n",
        "!wget https://downloads.apache.org/hbase/2.4.15/hbase-2.4.15-bin.tar.gz\n",
        "#!wget https://downloads.apache.org/hbase/2.5.0/hbase-2.5.0-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.5-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.8-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.9-bin.tar.gz\n",
        "!tar xzf hbase-2.4.15-bin.tar.gz\n",
        "#!tar xzf hbase-2.5.0-bin.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-07 06:48:54--  https://downloads.apache.org/hbase/2.4.15/hbase-2.4.15-bin.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 284230281 (271M) [application/x-gzip]\n",
            "Saving to: ‘hbase-2.4.15-bin.tar.gz’\n",
            "\n",
            "hbase-2.4.15-bin.ta 100%[===================>] 271.06M  18.3MB/s    in 16s     \n",
            "\n",
            "2022-11-07 06:49:11 (17.1 MB/s) - ‘hbase-2.4.15-bin.tar.gz’ saved [284230281/284230281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaMtyNOVCiMS"
      },
      "source": [
        "## Set HBase Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4dc0K7h4f-y",
        "outputId": "5343ed2f-6f03-4291-d542-28e081fd3558"
      },
      "source": [
        "#os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "#!echo $HIVE_HOME\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.5/\"\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.8/\"\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.9/\"\n",
        "os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.15/\"\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.5.0/\"\n",
        "!echo $HBASE_HOME\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hbase-2.4.15/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXZ_kF65VXK",
        "outputId": "9e9e406e-056a-46a5-b160-6eed011d07ea"
      },
      "source": [
        "# current_path taken from command in previous cell\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "#new_path = current_path+':/content/hbase-2.4.5/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "#new_path = current_path+':/content/hbase-2.4.8/bin'\n",
        "#new_path = current_path+':/content/hbase-2.4.9/bin'\n",
        "new_path = current_path+':/content/hbase-2.4.15/bin'\n",
        "#new_path = current_path+':/content/hbase-2.5.0/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.3/bin/:/content/hbase-2.4.15/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrS6BL5k51Bl",
        "outputId": "ba0846f1-e9af-4f76-f90e-e2ba0ece3153"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HBASE_HOME"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.3/\n",
            "/content/hbase-2.4.15/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kDmgFfh6a12"
      },
      "source": [
        "# the file hbase-site.xml may need to be updated ...\n",
        "# however the default file works well in the simple stand-alone HBase mode\n",
        "# so no need to touch it\n",
        "#!cat $HBASE_HOME/conf/hbase-site.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWn-DJ1PDbXd"
      },
      "source": [
        "## Some Clean UP\n",
        "Otherwise we get ugly warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKG7t8sQDj2t",
        "outputId": "894d0ca8-f557-4e41-a892-3551c9dde0f9"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HBASE_HOME/lib/*slf4j*\n",
        "!ls /content/hbase-2.4.15/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar\n",
        "#!ls /content/hbase-2.5.0/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/slf4j-api-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.3//share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar\n",
            "/content/hbase-2.4.15//lib/jcl-over-slf4j-1.7.33.jar\n",
            "/content/hbase-2.4.15//lib/jul-to-slf4j-1.7.33.jar\n",
            "/content/hbase-2.4.15/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### to avoid the logging issues of hadoop and hbase, we removed hbase and retained the hadoop. A logger keeps track whatever is happenning and it logs files.so, in case of problems, we have some chnaces to look at those files and find out what went wrong where."
      ],
      "metadata": {
        "id": "hlgQAdej3L1J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaOkjD5EOr0"
      },
      "source": [
        "# remove the Hadoop logger out of the path\n",
        "# without this you will get ugly warnings every time\n",
        "#!mv /usr/local/hadoop-3.3.0//share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar .\n",
        "!mv /content/hbase-2.4.15/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar .\n",
        "#!mv /content/hbase-2.5.0/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar ."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA03iA4XFN_E"
      },
      "source": [
        "## Start HBase server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMQHzlCO7MDC",
        "outputId": "abb912ef-4d97-4317-acbd-f80178f29299"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.15//logs/hbase--master-ccf30333b2f5.out\n",
            "1672 Jps\n",
            "1518 HMaster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1518 is a process id of HMaster, as of now we dont require it, but when we want to abort a process, we can use it."
      ],
      "metadata": {
        "id": "Ozp4-KkN41FC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6mdgPSFSvB"
      },
      "source": [
        "# Run Hbase Shell\n",
        "do not skip these two shell commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42DJQfpY7oqe"
      },
      "source": [
        "# you can enter hbase shell commands at the prompt. Double click on the prompt to open up a input box\n",
        "#!hbase shell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhuHJF4lH6f6"
      },
      "source": [
        "shell commands  <br>\n",
        "https://www.tutorialspoint.com/hbase/hbase_shell.htm <br>\n",
        "https://www.guru99.com/hbase-shell-general-commands.html <br>\n",
        "better way of passing shell commands are given here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdbisL2GQtE",
        "outputId": "9da3a8be-1370-48b7-bb04-86a035b98d44"
      },
      "source": [
        "!echo 'status' | hbase shell -n\n",
        "#!echo \"status 'detail'\" | hbase shell -n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hbase:001:0> status\n",
            "1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load\n",
            "Took 1.2121 seconds                                                             \n",
            "hbase:002:0> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYhR2DpgIbnU",
        "outputId": "212d8a0c-9206-460e-d82c-fe146849d427"
      },
      "source": [
        "!echo \"whoami\" | hbase shell -n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hbase:001:0> whoami\n",
            "root (auth:SIMPLE)\n",
            "    groups: root\n",
            "Took 0.0250 seconds                                                             \n",
            "hbase:002:0> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### It gave a proper answer back, which means HBase is alive and working."
      ],
      "metadata": {
        "id": "Gmzzy_Af5ipx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMwSSDZd6T9"
      },
      "source": [
        "#Install HappyBase / Thrift <br>\n",
        "https://happybase.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### It opens up a connection. It keeps the connection alive which means when we are sending a second query in, the earlier one is not died.In the previous approach. in each command waking up hadoop, waking up hbase, doing our jobs,it was a lengthy process, and takes a lots of time. Here, thrift server is always connected, so, its an alive database."
      ],
      "metadata": {
        "id": "HDIkRLCYt-cF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qOwqJlQfQLc",
        "outputId": "3f26a482-dfed-4d6d-d405-1f561b3f7bc0"
      },
      "source": [
        "!stop-hbase.sh"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### server program is also called demon, something is running at the background, it doesnot sstop until we stop it.In normal program, either it gives errors or stops, but a server program is not designed to stop,it is designed to stay awake and listen to other commands."
      ],
      "metadata": {
        "id": "GJ-Grmvl6BOL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLfCN8jpZsZH",
        "outputId": "1054e1a7-4ef3-4e2b-adf0-09f7ee07347e"
      },
      "source": [
        "!pip -qq install happybase"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 40 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 361 kB 13.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s \n",
            "\u001b[?25h  Building wheel for happybase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HappyBase is a developer-friendly Python library to interact with Apache HBase."
      ],
      "metadata": {
        "id": "TxVYqdD-7S5R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Wt2asZZb3m"
      },
      "source": [
        "import happybase\n",
        "#https://happybase.readthedocs.io/en/latest/"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now, we will use hbase-demon to start the thrift"
      ],
      "metadata": {
        "id": "VpGnEPzA8HFL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-OVMxNEaWOq",
        "outputId": "881310ce-3736-46d9-9a28-8053fb97ebf6"
      },
      "source": [
        "#!ls hbase-2.4.8/bin\n",
        "#!hbase-2.4.8/bin/hbase-daemon.sh start thrift\n",
        "!hbase-daemon.sh start thrift"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running thrift, logging to /content/hbase-2.4.15//logs/hbase--thrift-ccf30333b2f5.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHyIyGFf0yl",
        "outputId": "a8aa3c97-d5e2-44a9-cef4-32ae07c132d4"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.15//logs/hbase--master-ccf30333b2f5.out\n",
            "2949 ThriftServer\n",
            "3317 HMaster\n",
            "3471 Jps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### so, here along with HMaster, ThriftServer is also running in the system. so, two servers are running."
      ],
      "metadata": {
        "id": "pufR1qvx8d0L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uL64b823-CB"
      },
      "source": [
        "#connection = happybase.Connection('localhost',9090, transport='framed',protocol='compact')\n",
        "#if this connection suddenly closes, you may get errors. in that case, re-run this cell again\n",
        "kxn = happybase.Connection('localhost',9090,autoconnect=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4yg79ueMhYZ"
      },
      "source": [
        "#Create Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFjctMtoeCcW",
        "outputId": "5ee7e2a8-3281-4dd8-8633-92ce74deea4c"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### right now, we have not created any tables, so it is an empty list"
      ],
      "metadata": {
        "id": "exABXVZB9jbM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvAuebzbXj6"
      },
      "source": [
        "##Create Dept Table, Insert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiUqgnVCMcl3"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Dept')\n",
        "#kxn.delete_table('Dept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Dept',\n",
        "    {'DeptID': dict(max_versions=10),\n",
        "     'DeptName': dict(max_versions=1, block_cache_enabled=False),\n",
        "     'ManagerID': dict(),  # use defaults\n",
        "     'Location': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### codes are similar to mysql but here is no varchar, int because we are here defining only just column families which are basically dictionaries. in each column family, columns are very much flexible."
      ],
      "metadata": {
        "id": "pQmmdVhH-IJ9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsULtvF6Nfcx"
      },
      "source": [
        "kxn.open()\n",
        "tDept = kxn.table('Dept')\n",
        "kxn.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### so, we defined a table called tDept which refers to the Hbase table"
      ],
      "metadata": {
        "id": "qAeEwdGy-0JO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jju96MNoCf"
      },
      "source": [
        "#Insert one row\n",
        "kxn.open()\n",
        "tDept.put('10',{'DeptName:': 'Corporate', 'ManagerID:': '123456','Location:':'Calcutta'})\n",
        "kxn.close()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now, we want to see the data, and it looks like this"
      ],
      "metadata": {
        "id": "QCsC1V9C_HLS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP5nd0nIOTxf",
        "outputId": "b9b695f4-dfed-4440-d527-918061c235eb"
      },
      "source": [
        "kxn.open()\n",
        "for key, data in tDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Y9zgCJOywZ"
      },
      "source": [
        "#Insert 3 more rows in Batch\n",
        "kxn.open()\n",
        "b = tDept.batch()\n",
        "b.put(b'20', { b'DeptName:': b'Sales', b'ManagerID:': b'234567', b'Location:': b'Calcutta'})\n",
        "b.put(b'30', { b'DeptName:': b'Accounts', b'ManagerID:': b'567234', b'Location:': b'Calcutta'})\n",
        "b.put(b'40', { b'DeptName:': b'Production', b'ManagerID:': b'345876', b'Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn9puFvNSQ0I",
        "outputId": "ec879687-1f4b-41be-b1cb-fb3acbfdb176"
      },
      "source": [
        "#show all four ROWS\n",
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, value in tDept.scan():\n",
        "    print(key, value)\n",
        "kxn.close()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n",
            "b'20' {b'DeptName:': b'Sales', b'Location:': b'Calcutta', b'ManagerID:': b'234567'}\n",
            "b'30' {b'DeptName:': b'Accounts', b'Location:': b'Calcutta', b'ManagerID:': b'567234'}\n",
            "b'40' {b'DeptName:': b'Production', b'Location:': b'Bombay', b'ManagerID:': b'345876'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjTzUYObi7W"
      },
      "source": [
        "##Create Emp Table, LOAD data <br>\n",
        "https://people.apache.org/~stack/site/bulk-loads.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GbQWvRcTwu"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Emp')\n",
        "#kxn.delete_table('Emp')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Emp',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'LastName': dict(),  # use defaults\n",
        "     'FirstName': dict(),  # use defaults\n",
        "     'Role': dict(),  # use defaults\n",
        "     'DoJ': dict(),  # use defaults\n",
        "     'Salary': dict(),  # use defaults\n",
        "     'Comm': dict(),  # use defaults\n",
        "     'DeptID': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XDyx1HQxBL",
        "outputId": "89af81d0-3196-461b-9289-44a0274d065d"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYH_g_J6423R"
      },
      "source": [
        "#Download txt file with Employee Data\n",
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/Employee.csv"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cat Employee.csv"
      ],
      "metadata": {
        "id": "Hmd38X4s1bmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mqsql can read the files from local file system, but anything on hadoop doesnot read the file from local file system, it only reads the hdfs file system. so, I have to move my data from my local file system to hdfs file system."
      ],
      "metadata": {
        "id": "mk_BCr02AWhf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZbsNgyBd-aN"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal Employee.csv /tmp"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now we have to load the data, by ImportTsv command"
      ],
      "metadata": {
        "id": "SAQ_jXO-BH8j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFRp3yateTCS"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,LastName:,FirstName:,Role:,DoJ:,Salary:,Comm:,DeptID:\" Emp /tmp/Employee.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxvMPuZ8gOW5"
      },
      "source": [
        "kxn.open()\n",
        "tEmp = kxn.table('Emp')\n",
        "kxn.close()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uonqOE2AgXeq",
        "outputId": "c35ce240-0260-4a03-ab21-0573c787fef2"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmp.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Comm:': b'0.02', b'DeptID:': b'40', b'DoJ:': b'2004-10-09', b'FirstName:': b'Mahender', b'LastName:': b'Dhoni', b'Role:': b'Clerk', b'Salary:': b'9000'}\n",
            "b'223112' {b'Comm:': b'0.04', b'DeptID:': b'30', b'DoJ:': b'2001-11-19', b'FirstName:': b'Sania', b'LastName:': b'Mirza', b'Role:': b'Cus_Rep', b'Salary:': b'25000'}\n",
            "b'239456' {b'Comm:': b'0.07', b'DeptID:': b'20', b'DoJ:': b'2004-01-03', b'FirstName:': b'Shahrukh', b'LastName:': b'Khan', b'Role:': b'Manager', b'Salary:': b'30000'}\n",
            "b'299034' {b'Comm:': b'0.11', b'DeptID:': b'10', b'DoJ:': b'2002-10-10', b'FirstName:': b'Rekha', b'LastName:': b'Ganesan', b'Role:': b'Director', b'Salary:': b'60000'}\n",
            "b'349870' {b'Comm:': b'0.06', b'DeptID:': b'40', b'DoJ:': b'2005-05-04', b'FirstName:': b'Rani', b'LastName:': b'Mukherjee', b'Role:': b'Manager', b'Salary:': b'25000'}\n",
            "b'546223' {b'Comm:': b'0.09', b'DeptID:': b'10', b'DoJ:': b'2005-12-04', b'FirstName:': b'Narayan', b'LastName:': b'Karthikeyan', b'Role:': b'Secretary', b'Salary:': b'40000'}\n",
            "b'742866' {b'Comm:': b'0.1', b'DeptID:': b'10', b'DoJ:': b'2003-03-10', b'FirstName:': b'Amitabh', b'LastName:': b'Bacchan', b'Role:': b'Executive', b'Salary:': b'50000'}\n",
            "b'822134' {b'Comm:': b'0.08', b'DeptID:': b'30', b'DoJ:': b'2000-06-04', b'FirstName:': b'Rahul', b'LastName:': b'Dravid', b'Role:': b'Sr Manager', b'Salary:': b'40000'}\n",
            "b'865477' {b'Comm:': b'0.02', b'DeptID:': b'20', b'DoJ:': b'2002-04-04', b'FirstName:': b'Madhuri', b'LastName:': b'Dikshit', b'Role:': b'Clerk', b'Salary:': b'10000'}\n",
            "b'897889' {b'Comm:': b'0.05', b'DeptID:': b'20', b'DoJ:': b'2005-01-02', b'FirstName:': b'Virender', b'LastName:': b'Sehwag', b'Role:': b'Cus_Rep', b'Salary:': b'15000'}\n",
            "b'989007' {b'Comm:': b'0.03', b'DeptID:': b'40', b'DoJ:': b'2002-01-01', b'FirstName:': b'Sourav', b'LastName:': b'Ganguly', b'Role:': b'Cus_Rep', b'Salary:': b'20000'}\n",
            "b'997445' {b'Comm:': b'0.02', b'DeptID:': b'30', b'DoJ:': b'2001-07-01', b'FirstName:': b'Jagmohan', b'LastName:': b'Dalmia', b'Role:': b'Clerk', b'Salary:': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS__XdMYjLzd"
      },
      "source": [
        "## Creating, INSERTing Denormalised EmpDept Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQRpLsmfjbgp"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('EmpDept')\n",
        "#kxn.delete_table('EmpDept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### here, we cannot use normal join just like we did in mysql, but we are creating a table where two column families are Emp and Dept which are tables themselves."
      ],
      "metadata": {
        "id": "3PwrFM-6C2M7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6Zk4bKqMas",
        "outputId": "260d0841-cb9e-4af1-a5ef-d795a4d9863b"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duGwwpF1n5IG"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept = kxn.table('EmpDept')\n",
        "b = tEmpDept.batch()\n",
        "b.put(b'742866', { b'Emp:FirstName': b'Amitabh', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta'})\n",
        "b.put(b'349870', { b'Emp:LastName': b'Mukheree', b'Dept:ManagerID': b'567234', b'Dept:Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzxFRXp7rS87",
        "outputId": "4640ca83-1158-4180-b849-c68f28a025f6"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmpDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'349870' {b'Dept:Location:': b'Bombay', b'Dept:ManagerID': b'567234', b'Emp:LastName': b'Mukheree'}\n",
            "b'742866' {b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Emp:FirstName': b'Amitabh'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWZKpJ_LtMnQ"
      },
      "source": [
        "##Creating and LOADing denormalised tables EmpDept2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giAKNFnMtJ-b"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('EmpDept2')\n",
        "#kxn.delete_table('EmpDept2')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept2',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WwCA4euf-i",
        "outputId": "3fec712c-ded1-4e68-b7dd-f6a2ea9a7efb"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept', b'EmpDept2']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now, we are loading a bulk data. however, here flexibility of having different columns doesnot work becuase loading the data in hdfs we to mention all the specified columns"
      ],
      "metadata": {
        "id": "2zb93NuTGvCy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fijaJ_G5ktF"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/EmployeeDept2.txt"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat EmployeeDept2.txt"
      ],
      "metadata": {
        "id": "319EWjdEB5yn",
        "outputId": "4da2ba4a-3931-4da4-e9c5-38a0e5a9b8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "742866,Bacchan,Amitabh,Executive,2003-03-10,50000,0.1,10,Corporate,299034,Calcutta\n",
            "349870,Mukherjee,Rani,Manager,2005-05-04,25000,0.06,40,Production,349870,Bombay\n",
            "865477,Dikshit,Madhuri,Clerk,2002-04-04,10000,0.02,20,Sales,239456,Calcutta\n",
            "239456,Khan,Shahrukh,Manager,2004-01-03,30000,0.07,20,Sales,239456,Calcutta\n",
            "897889,Sehwag,Virender,Cus_Rep,2005-01-02,15000,0.05,20,Sales,239456,Calcutta\n",
            "123980,Dhoni,Mahender,Clerk,2004-10-09,9000,0.02,40,Production,349870,Bombay\n",
            "822134,Dravid,Rahul,Sr Manager,2000-06-04,40000,0.08,30,Accounts,822134,Calcutta\n",
            "997445,Dalmia,Jagmohan,Clerk,2001-07-01,12000,0.02,30,Accounts,822134,Calcutta\n",
            "989007,Ganguly,Sourav,Cus_Rep,2002-01-01,20000,0.03,40,Production,349870,Bombay\n",
            "299034,Ganesan,Rekha,Director,2002-10-10,60000,0.11,10,Corporate,299034,Calcutta\n",
            "546223,Karthikeyan,Narayan,Secretary,2005-12-04,40000,0.09,10,Corporate,299034,Calcutta\n",
            "223112,Mirza,Sania,Cus_Rep,2001-11-19,25000,0.04,30,Accounts,822134,Calcutta"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvItjBLuu7oM"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal EmployeeDept2.txt /tmp"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_VFWQZJvXqn"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,Emp:LastName,Emp:FirstName,Emp:Role,Emp:DoJ,Emp:Salary,Emp:Comm,Dept:DeptID,Dept:DeptName,Dept:ManagerID,Dept:Location\" EmpDept2 /tmp/EmployeeDept2.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-H5Zh5UwRzd"
      },
      "source": [
        "tEmpDept2 = kxn.table('EmpDept2')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4tQppiqwMTk",
        "outputId": "0bc2d3ac-91b7-4220-c3fa-428b1a81e4a4"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n",
            "b'223112' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.04', b'Emp:DoJ': b'2001-11-19', b'Emp:FirstName': b'Sania', b'Emp:LastName': b'Mirza', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'25000'}\n",
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n",
            "b'989007' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.03', b'Emp:DoJ': b'2002-01-01', b'Emp:FirstName': b'Sourav', b'Emp:LastName': b'Ganguly', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'20000'}\n",
            "b'997445' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2001-07-01', b'Emp:FirstName': b'Jagmohan', b'Emp:LastName': b'Dalmia', b'Emp:Role': b'Clerk', b'Emp:Salary': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIY0y-OO1rV"
      },
      "source": [
        "#Data Retrieval <br>\n",
        "https://happybase.readthedocs.io/en/latest/user.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmYXOCEO-EJ",
        "outputId": "1aea9cbc-d113-4fae-daeb-3d084bf03e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive One Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "prow = tEmpDept2.row(b'123980')\n",
        "print(prow)   # prints the value of cf1:col1"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### so, we retreived the data of single row by speciftying the key"
      ],
      "metadata": {
        "id": "fVgOH12PH8Nu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azcfxg2YP9AH",
        "outputId": "f5d86e16-e632-47be-9be1-d57d3672386e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "listOfrows = [b'742866', b'897889']\n",
        "rows = tEmpDept2.rows(listOfrows)\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69-NH_HcQ84G",
        "outputId": "f38ec18c-c828-4791-fa86-a5228c69c58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rowsDict = dict(tEmpDept2.rows([b'742866', b'897889']))\n",
        "for k,v in rowsDict.items():\n",
        "    print(k,v)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25jvHL81TwcN",
        "outputId": "038c558d-c720-4b2a-a3fd-7e19257de440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Emp'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'897889' {b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT0svpwPUOUo",
        "outputId": "22909724-df36-4c7e-912f-00f2192c5f92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Dept'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxjJtKhrUWwM",
        "outputId": "49388ea4-23cd-47ac-ebeb-3fa4f3a6f24e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Retreive More than one Row, but only one column family\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "rows = tEmpDept2.rows([b'742866', b'897889'],columns=[b'Emp:LastName',b'Dept:Location'])\n",
        "for key, data in rows:\n",
        "    print(key, data)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'742866' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Bacchan'}\n",
            "b'897889' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Sehwag'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQs2EH6OU74d",
        "outputId": "29af6391-ce6b-489a-8062-61744943c15e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n",
            "b'223112' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.04', b'Emp:DoJ': b'2001-11-19', b'Emp:FirstName': b'Sania', b'Emp:LastName': b'Mirza', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'25000'}\n",
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n",
            "b'989007' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.03', b'Emp:DoJ': b'2002-01-01', b'Emp:FirstName': b'Sourav', b'Emp:LastName': b'Ganguly', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'20000'}\n",
            "b'997445' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2001-07-01', b'Emp:FirstName': b'Jagmohan', b'Emp:LastName': b'Dalmia', b'Emp:Role': b'Clerk', b'Emp:Salary': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2Qhg60VEtX",
        "outputId": "46f1609e-c299-4c5b-993a-9999f3140b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan(row_start=b'230000', row_stop=b'870000'):\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXl-QezFVXSS",
        "outputId": "cd74686e-7a59-4090-efd4-91e9d51e7b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#kxn = happybase.Connection('localhost',9090,autoconnect=False)\n",
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan(row_start=b'230000', row_stop=b'870000',columns=[b'Emp:LastName',b'Dept:Location']):\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'239456' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Khan'}\n",
            "b'299034' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Ganesan'}\n",
            "b'349870' {b'Dept:Location': b'Bombay', b'Emp:LastName': b'Mukherjee'}\n",
            "b'546223' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Karthikeyan'}\n",
            "b'742866' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Bacchan'}\n",
            "b'822134' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Dravid'}\n",
            "b'865477' {b'Dept:Location': b'Calcutta', b'Emp:LastName': b'Dikshit'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PP3akdlVKJ"
      },
      "source": [
        "#Stop HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p28XBoitAWTL",
        "outputId": "6ff2774f-6637-49d4-a5ed-5b7c6c8ba765"
      },
      "source": [
        "!stop-hbase.sh\n",
        "!date"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase..............\n",
            "Mon Nov  7 08:12:10 UTC 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### so, sql is much more convenient, we can use group by order by ,but here we can't do that. if we want to do that, we have to do that manually after retreiving the data we want. but hbase works on petabyte of data and it is fast. so, there is a trade-off between speed and convenience ,so, habse is not convenient because here there is no richness of sql language but has high performance, and all of them fall under category of cluster computing."
      ],
      "metadata": {
        "id": "mfZ6QPbEJ9B7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cJplaS9LS8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}